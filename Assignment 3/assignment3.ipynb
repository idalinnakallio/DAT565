{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import pandas as pd\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Spam and Ham data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fn):\n",
    "    dataset = list()\n",
    "    with tarfile.open(fn) as tf:\n",
    "        for i in tf:\n",
    "            if i.isfile():\n",
    "                with tf.extractfile(i) as f:\n",
    "                    b  = f.read()\n",
    "                    if b'charset=utf-8' in b or b'charset=UTF-8' in b:\n",
    "                        s = b.decode('utf-8')\n",
    "                    else:\n",
    "                        s = b.decode('iso-8859-1')\n",
    "                    dataset.append(s)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'easy_ham': read_data('data/20021010_easy_ham.tar.bz2'),\n",
    "    'hard_ham': read_data('data/20021010_hard_ham.tar.bz2'),\n",
    "    'spam': read_data('data/20021010_spam.tar.bz2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eh = pd.DataFrame(data['easy_ham']) \n",
    "df_hh = pd.DataFrame(data['hard_ham'])\n",
    "df_spam = pd.DataFrame(data['spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eh.rename(columns={0: 'email'}, inplace=True)\n",
    "df_hh.rename(columns={0: 'email'}, inplace=True)\n",
    "df_spam.rename(columns={0: 'email'}, inplace=True)\n",
    "\n",
    "df_eh['label'] = 'easy_ham'\n",
    "df_hh['label'] = 'hard_ham'\n",
    "df_spam['label'] = 'spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From george@vccomputers.ie  Mon Aug 26 17:49:4...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From gwfqjulie@msn.com  Mon Aug 26 21:37:20 20...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From simply-amateur-zzzz=example.com@free4porn...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From thisisagreatfreepornmovie@framesetup.com ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From safety33o@l4.newnamedns.com  Tue Aug 27 0...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>From havoc1006@yahoo.com  Mon Aug 26 15:49:43 ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>From mando@insiq.us  Mon Aug 26 15:49:52 2002\\...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>From girl_with_toys_541652k57@yahoo.com  Mon A...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>From guyhaibo@yahoo.ca  Mon Aug 26 15:50:05 20...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>mv 1 00001.bfc8d64d12b325ff385cca8d07b84288\\nm...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 email label\n",
       "0    From george@vccomputers.ie  Mon Aug 26 17:49:4...  spam\n",
       "1    From gwfqjulie@msn.com  Mon Aug 26 21:37:20 20...  spam\n",
       "2    From simply-amateur-zzzz=example.com@free4porn...  spam\n",
       "3    From thisisagreatfreepornmovie@framesetup.com ...  spam\n",
       "4    From safety33o@l4.newnamedns.com  Tue Aug 27 0...  spam\n",
       "..                                                 ...   ...\n",
       "496  From havoc1006@yahoo.com  Mon Aug 26 15:49:43 ...  spam\n",
       "497  From mando@insiq.us  Mon Aug 26 15:49:52 2002\\...  spam\n",
       "498  From girl_with_toys_541652k57@yahoo.com  Mon A...  spam\n",
       "499  From guyhaibo@yahoo.ca  Mon Aug 26 15:50:05 20...  spam\n",
       "500  mv 1 00001.bfc8d64d12b325ff385cca8d07b84288\\nm...  spam\n",
       "\n",
       "[501 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eh.to_csv(\"eh_content.csv\")\n",
    "df_hh.to_csv(\"hh_content.csv\")\n",
    "df_spam.to_csv(\"spam_content.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train-test split for df_spam\n",
    "X_train_spam, X_test_spam, y_train_spam, y_test_spam = train_test_split(df_spam['email'], df_spam['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split for df_eh\n",
    "X_train_eh, X_test_eh, y_train_eh, y_test_eh = train_test_split(df_eh['email'], df_eh['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split for df_hh\n",
    "X_train_hh, X_test_hh, y_train_hh, y_test_hh = train_test_split(df_hh['email'], df_hh['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_eh = CountVectorizer()\n",
    "count_hh = CountVectorizer()\n",
    "\n",
    "# Concatenating the spam training data with the two different ham datas\n",
    "X_train_eh_spam = pd.concat([X_train_spam, X_train_eh],ignore_index=True)\n",
    "X_train_hh_spam = pd.concat([X_train_spam, X_train_hh],ignore_index=True)\n",
    "\n",
    "y_train_eh_spam = pd.concat([y_train_spam, y_train_eh],ignore_index=True)\n",
    "y_train_hh_spam = pd.concat([y_train_spam, y_train_hh],ignore_index=True)\n",
    "\n",
    "# Transforming the concatenated training data into a document-term matrix \n",
    "# and fits the count vectorizer to the training data\n",
    "X_train_eh_spam = count_eh.fit_transform(X_train_eh_spam)\n",
    "X_train_hh_spam = count_hh.fit_transform(X_train_hh_spam)\n",
    "\n",
    "# Apply the same transformation on the test data\n",
    "X_test_eh_spam = pd.concat([X_test_spam, X_test_eh],ignore_index=True)\n",
    "X_test_hh_spam = pd.concat([X_test_spam, X_test_hh],ignore_index=True)\n",
    "\n",
    "y_test_eh_spam = pd.concat([y_test_spam, y_test_eh],ignore_index=True)\n",
    "y_test_hh_spam = pd.concat([y_test_spam, y_test_hh],ignore_index=True)\n",
    "\n",
    "X_test_eh_spam = count_eh.transform(X_test_eh_spam)\n",
    "X_test_hh_spam = count_hh.transform(X_test_hh_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Instantiate classifiers\n",
    "multinomial_nb = MultinomialNB()\n",
    "bernoulli_nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifiers on the training data\n",
    "multinomial_nb.fit(X_train_eh_spam, y_train_eh_spam)\n",
    "bernoulli_nb.fit(X_train_eh_spam, y_train_eh_spam)\n",
    "\n",
    "# Make predictions on the test set\n",
    "multinomial_nb_preds = multinomial_nb.predict(X_test_eh_spam)\n",
    "bernoulli_nb_preds = bernoulli_nb.predict(X_test_eh_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Calculate accuracy, precision and recall for Multinomial Naive Bayes Classifier \n",
    "multinomial_accuracy = accuracy_score(y_test_eh_spam, multinomial_nb_preds)\n",
    "multinomial_precision = precision_score(y_test_eh_spam, multinomial_nb_preds, pos_label='spam')\n",
    "multinomial_recall = recall_score(y_test_eh_spam, multinomial_nb_preds, pos_label='spam')\n",
    "\n",
    "# Calculate confusion matrix for Multinomial Naive Bayes Classifier\n",
    "multinomial_conf_matrix = confusion_matrix(y_test_eh_spam, multinomial_nb_preds)\n",
    "\n",
    "# Calculate accuracy, precision and recall for Bernoulli Naive Bayes Classifier\n",
    "bernoulli_accuracy = accuracy_score(y_test_eh_spam, bernoulli_nb_preds)\n",
    "bernoulli_precision = precision_score(y_test_eh_spam, bernoulli_nb_preds, pos_label='spam')\n",
    "bernoulli_recall = recall_score(y_test_eh_spam, bernoulli_nb_preds, pos_label='spam')\n",
    "\n",
    "# Calculate confusion matrix for Bernoulli Naive Bayes Classifier\n",
    "bernoulli_conf_matrix = confusion_matrix(y_test_eh_spam, bernoulli_nb_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier Accuracy: 0.9624183006535948\n",
      "Multinomial Naive Bayes Classifier Precision: 0.9875\n",
      "Multinomial Naive Bayes Classifier Recall: 0.7821782178217822\n",
      "Multinomial Naive Bayes Classifier Confusion Matrix:\n",
      "[[510   1]\n",
      " [ 22  79]]\n",
      "Bernoulli Naive Bayes Classifier Accuracy: 0.9019607843137255\n",
      "Bernoulli Naive Bayes Classifier Precision: 0.9767441860465116\n",
      "Bernoulli Naive Bayes Classifier Recall: 0.4158415841584158\n",
      "Bernoulli Naive Bayes Classifier Confusion Matrix:\n",
      "[[510   1]\n",
      " [ 59  42]]\n"
     ]
    }
   ],
   "source": [
    "# Print Multinomial Naive Bayes Classifier results\n",
    "print(\"Multinomial Naive Bayes Classifier Accuracy:\", multinomial_accuracy)\n",
    "print(\"Multinomial Naive Bayes Classifier Precision:\", multinomial_precision)\n",
    "print(\"Multinomial Naive Bayes Classifier Recall:\", multinomial_recall)\n",
    "print(\"Multinomial Naive Bayes Classifier Confusion Matrix:\")\n",
    "print(multinomial_conf_matrix)\n",
    "\n",
    "# Print Bernoulli Naive Bayes Classifier results\n",
    "print(\"Bernoulli Naive Bayes Classifier Accuracy:\", bernoulli_accuracy)\n",
    "print(\"Bernoulli Naive Bayes Classifier Precision:\", bernoulli_precision)\n",
    "print(\"Bernoulli Naive Bayes Classifier Recall:\", bernoulli_recall)\n",
    "print(\"Bernoulli Naive Bayes Classifier Confusion Matrix:\")\n",
    "print(bernoulli_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifiers\n",
    "multinomial_nb_hh = MultinomialNB()\n",
    "bernoulli_nb_hh = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifiers on the training data\n",
    "multinomial_nb_hh.fit(X_train_hh_spam, y_train_hh_spam)\n",
    "bernoulli_nb_hh.fit(X_train_hh_spam, y_train_hh_spam)\n",
    "\n",
    "# Make predictions on the test set\n",
    "multinomial_nb_preds_hh = multinomial_nb_hh.predict(X_test_hh_spam)\n",
    "bernoulli_nb_preds_hh = bernoulli_nb_hh.predict(X_test_hh_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, precision and recall for Multinomial Naive Bayes Classifier \n",
    "multinomial_accuracy_hh = accuracy_score(y_test_hh_spam, multinomial_nb_preds_hh)\n",
    "multinomial_precision_hh = precision_score(y_test_hh_spam, multinomial_nb_preds_hh, pos_label='spam')\n",
    "multinomial_recall_hh = recall_score(y_test_hh_spam, multinomial_nb_preds_hh, pos_label='spam')\n",
    "\n",
    "# Calculate confusion matrix for Multinomial Naive Bayes Classifier\n",
    "multinomial_conf_matrix_hh = confusion_matrix(y_test_hh_spam, multinomial_nb_preds_hh)\n",
    "\n",
    "# Calculate accuracy, precision and recall for Bernoulli Naive Bayes Classifier\n",
    "bernoulli_accuracy_hh = accuracy_score(y_test_hh_spam, bernoulli_nb_preds_hh)\n",
    "bernoulli_precision_hh = precision_score(y_test_hh_spam, bernoulli_nb_preds_hh, pos_label='spam')\n",
    "bernoulli_recall_hh = recall_score(y_test_hh_spam, bernoulli_nb_preds_hh, pos_label='spam')\n",
    "\n",
    "# Calculate confusion matrix for Bernoulli Naive Bayes Classifier\n",
    "bernoulli_conf_matrix_hh = confusion_matrix(y_test_hh_spam, bernoulli_nb_preds_hh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier Accuracy: 0.9735099337748344\n",
      "Multinomial Naive Bayes Classifier Precision: 0.9619047619047619\n",
      "Multinomial Naive Bayes Classifier Recall: 1.0\n",
      "Multinomial Naive Bayes Classifier Confusion Matrix:\n",
      "[[ 46   4]\n",
      " [  0 101]]\n",
      "Bernoulli Naive Bayes Classifier Accuracy: 0.9006622516556292\n",
      "Bernoulli Naive Bayes Classifier Precision: 0.8839285714285714\n",
      "Bernoulli Naive Bayes Classifier Recall: 0.9801980198019802\n",
      "Bernoulli Naive Bayes Classifier Confusion Matrix:\n",
      "[[37 13]\n",
      " [ 2 99]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print Multinomial Naive Bayes Classifier results\n",
    "print(\"Multinomial Naive Bayes Classifier Accuracy:\", multinomial_accuracy_hh)\n",
    "print(\"Multinomial Naive Bayes Classifier Precision:\", multinomial_precision_hh)\n",
    "print(\"Multinomial Naive Bayes Classifier Recall:\", multinomial_recall_hh)\n",
    "print(\"Multinomial Naive Bayes Classifier Confusion Matrix:\")\n",
    "print(multinomial_conf_matrix_hh)\n",
    "\n",
    "# Print Bernoulli Naive Bayes Classifier results\n",
    "print(\"Bernoulli Naive Bayes Classifier Accuracy:\", bernoulli_accuracy_hh)\n",
    "print(\"Bernoulli Naive Bayes Classifier Precision:\", bernoulli_precision_hh)\n",
    "print(\"Bernoulli Naive Bayes Classifier Recall:\", bernoulli_recall_hh)\n",
    "print(\"Bernoulli Naive Bayes Classifier Confusion Matrix:\")\n",
    "print(bernoulli_conf_matrix_hh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
